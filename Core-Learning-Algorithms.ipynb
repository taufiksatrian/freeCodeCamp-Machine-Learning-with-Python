{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4iiRcnZ4sQxTbZgVo4KD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taufiksatrian/freeCodeCamp-Machine-Learning-with-Python/blob/main/Core-Learning-Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXZYKqP1JzII",
        "outputId": "a848542f-edee-4771-e26e-82ea89c98c96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj2m84BiJ3bh",
        "outputId": "848af1a6-8721-4a6c-f675-b08f12efca38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mbte7M_zECni"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck','embark_town', 'alone']\n",
        "NUMERICAL_COLUMNS = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  print\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERICAL_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "\n",
        "print(feature_columns)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQsztYUKEIUU",
        "outputId": "cd386134-3271-4649-fe67-600caacdb89b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain[feature_name].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN1pB2bGJ-Q_",
        "outputId": "c8a27b61-8a8b-493b-8259-3fd9e4de6b47"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  7.25  ,  71.2833,   7.925 ,  53.1   ,   8.4583,  21.075 ,\n",
              "        11.1333,  30.0708,  16.7   ,   8.05  ,  31.275 ,   7.8542,\n",
              "        29.125 ,  13.    ,  18.    ,   7.225 ,  26.    ,  35.5   ,\n",
              "        31.3875, 263.    ,   7.8792,   7.8958,  27.7208, 146.5208,\n",
              "         7.75  ,  10.5   ,  82.1708,  52.    ,   7.2292,  11.2417,\n",
              "         9.475 ,  21.    ,  41.5792,  15.5   ,  21.6792,  17.8   ,\n",
              "        39.6875,  76.7292,  61.9792,  46.9   ,  80.    ,  83.475 ,\n",
              "        27.9   ,  15.2458,   8.1583,   8.6625,  73.5   ,  56.4958,\n",
              "         7.65  ,  29.    ,  12.475 ,   9.    ,   9.5   ,   7.7875,\n",
              "        47.1   ,  34.375 ,  61.175 ,  34.6542,  63.3583,  23.    ,\n",
              "        77.2875,   8.6542,   7.775 ,  24.15  ,  14.4542,  14.4583,\n",
              "       247.5208,   7.1417,   6.975 ,   7.05  ,  14.5   ,  15.0458,\n",
              "        26.2833,   9.2167,  79.2   ,   6.75  ,  11.5   ,  12.525 ,\n",
              "         7.3125,  61.3792,   7.7333,  69.55  ,  16.1   ,  55.    ,\n",
              "        25.4667,  28.7125,   0.    ,  15.05  ,  22.025 ,  26.55  ,\n",
              "         6.4958,  10.4625,  15.85  ,  18.7875,  31.    , 113.275 ,\n",
              "        27.    ,   9.35  ,  13.5   ,   7.55  ,  12.275 ,   7.125 ,\n",
              "        90.    ,  20.2125, 512.3292, 153.4625, 135.6333,  19.5   ,\n",
              "        29.7   ,  77.9583,  20.25  ,  78.85  ,  12.875 ,  30.5   ,\n",
              "        12.35  , 110.8833, 108.9   ,  24.    ,  56.9292,  83.1583,\n",
              "       262.375 ,  26.25  , 164.8667, 134.5   ,   6.2375,  20.525 ,\n",
              "        23.25  , 133.65  ,  66.6   ,  75.25  ,  69.3   , 211.5   ,\n",
              "       227.525 ,   7.7292,  12.    , 120.    ,   7.7958,  18.75  ,\n",
              "         6.8583,  32.5   ,  55.9   ,   8.1125,  19.2583,  27.75  ,\n",
              "        89.1042,  51.8625,  38.5   ,   7.725 ,  13.7917,   7.0458,\n",
              "        12.2875,   9.5875,  91.0792,  15.9   ,  19.9667,  49.5042,\n",
              "       151.55  ,  59.4   ,   7.4958,  34.0208,  93.5   ,  57.9792,\n",
              "       221.7792,  22.3583, 106.425 ,  49.5   ,  71.    ,  13.8625,\n",
              "         7.8292,  39.6   ,  79.65  ,  17.4   ,  51.4792,  26.3875,\n",
              "        30.    ,  40.125 ,  15.    ,  78.2667,  33.    ,  15.55  ,\n",
              "        65.    ,  14.4   ,  15.7417,  32.3208,   7.0542,   8.4333,\n",
              "        25.5875,  39.    ,   9.8417,   9.225 ,  10.1708, 211.3375,\n",
              "        57.    ,  13.4167,  26.2875,   7.7417,   9.4833,   8.3625,\n",
              "        23.45  ,  20.575 ,  30.6958,  25.9292,   8.6833,   7.8875,\n",
              "        37.0042,   6.95  ,   8.3   ,   6.4375,  39.4   ,  14.1083,\n",
              "        13.8583,  50.4958,  52.5542,   5.    ,   9.8458,  10.5167])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain[\"sex\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HsIx1c0KJAq",
        "outputId": "875cf7cf-9408-4942-b422-44f97202acf6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['male', 'female'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Training Process"
      ],
      "metadata": {
        "id": "r26T2-x9Tc_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Function"
      ],
      "metadata": {
        "id": "s86GfAGnK5j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "metadata": {
        "id": "UkUAXMUKK8Rj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the Model"
      ],
      "metadata": {
        "id": "xusL-hh7OHky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
      ],
      "metadata": {
        "id": "MptE34hqMj2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "1bRa76_SOmLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "clear_output()\n",
        "print('Accuracy : ', result['accuracy'])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW_RAf6AOhXG",
        "outputId": "ca09e245-6a07-42d4-eb34-0f4c65909222"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.7689394\n",
            "{'accuracy': 0.7689394, 'accuracy_baseline': 0.625, 'auc': 0.8370676, 'auc_precision_recall': 0.790781, 'average_loss': 0.46921954, 'label/mean': 0.375, 'loss': 0.4566367, 'precision': 0.69, 'prediction/mean': 0.39163446, 'recall': 0.6969697, 'global_step': 600}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = list(linear_est.predict(eval_input_fn))\n",
        "print(dfeval.loc[2])\n",
        "print(y_eval.loc[2])\n",
        "print(result[2]['probabilities'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05yLyf8OQFXe",
        "outputId": "7b5eb56d-3ddb-46cb-f0ce-279e2e1f4984"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                        female\n",
            "age                          58.0\n",
            "n_siblings_spouses              0\n",
            "parch                           0\n",
            "fare                        26.55\n",
            "class                       First\n",
            "deck                            C\n",
            "embark_town           Southampton\n",
            "alone                           y\n",
            "Name: 2, dtype: object\n",
            "1\n",
            "0.2657789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificafication"
      ],
      "metadata": {
        "id": "P1_a7mLFSE7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Setup"
      ],
      "metadata": {
        "id": "V9DAKOlnTwet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0X4XJFiTmjf",
        "outputId": "f3753cab-37b4-4156-b5c9-646102a6b3f9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6qUcDIYtT4EZ"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}